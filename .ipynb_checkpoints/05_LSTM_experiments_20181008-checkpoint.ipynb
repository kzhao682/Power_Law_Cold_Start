{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ubuntu/scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starter import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2018\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_test = pd.read_csv('cold_start_test.csv', index_col=[0], parse_dates=[2])\n",
    "consumption_train = pd.read_csv('consumption_train.csv', index_col=[0], parse_dates=[2])\n",
    "meta = pd.read_csv('new_meta.csv', index_col=[0], converters={'days_off':str})\n",
    "submission_format = pd.read_csv('new_submission_format.csv', index_col=[0], parse_dates=[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select train and test series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_training_data(train_df):\n",
    "    num_training_series = train_df.series_id.nunique()\n",
    "    num_training_days = num_training_series * 28\n",
    "    num_training_hours = num_training_days * 24\n",
    "    assert num_training_hours == train_df.shape[0]\n",
    "    \n",
    "    desc = f'There are {num_training_series} training ' \\\n",
    "           f'series totaling {num_training_days} days ' \\\n",
    "           f'({num_training_hours} hours) of consumption data.'\n",
    "    \n",
    "    print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 758 training series totaling 21224 days (509376 hours) of consumption data.\n"
     ]
    }
   ],
   "source": [
    "describe_training_data(consumption_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 161 training series totaling 4508 days (108192 hours) of consumption data.\n"
     ]
    }
   ],
   "source": [
    "# choose subset of series for training\n",
    "frac_series_to_use = 0.2\n",
    "\n",
    "rng = np.random.RandomState(seed=RANDOM_SEED)\n",
    "series_ids = consumption_train.series_id.unique()\n",
    "series_mask = rng.binomial(1,\n",
    "                           frac_series_to_use,\n",
    "                           size=series_ids.shape).astype(bool)\n",
    "\n",
    "training_series = series_ids[series_mask]\n",
    "\n",
    "# reduce training data to series subset\n",
    "consumption_train = consumption_train[consumption_train.series_id.isin(training_series)]\n",
    "\n",
    "# describe the reduced set\n",
    "describe_training_data(consumption_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# choose subset of series to use\n",
    "frac_series_to_use = 0.1\n",
    "rng = np.random.RandomState(seed=RANDOM_SEED)\n",
    "series_ids = consumption_train.series_id.unique()\n",
    "series_mask = rng.binomial(1,\n",
    "                           frac_series_to_use,\n",
    "                           size=series_ids.shape).astype(bool)\n",
    "series_data = series_ids[series_mask]\n",
    "\n",
    "# allocate 1/3 of data to testing set\n",
    "test_series = series_data[rng.binomial(1, 0.2, size=series_data.shape).astype(bool)]\n",
    "train_series = [x for x in series_data if x not in test_series]\n",
    "\n",
    "# reduce training data to series subset\n",
    "consumption_test = consumption_train[consumption_train.series_id.isin(test_series)]\n",
    "consumption_train = consumption_train[consumption_train.series_id.isin(train_series)]\n",
    "\n",
    "# # describe the reduced set\n",
    "describe_training_data(consumption_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "series_id  prediction_window\n",
       "100004     weekly                4.0\n",
       "100010     hourly               12.0\n",
       "100012     hourly               10.0\n",
       "100020     weekly               13.0\n",
       "100028     daily                13.0\n",
       "Name: prediction_window, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add prediction_window to the test data\n",
    "pred_windows = submission_format[['series_id', 'prediction_window']].drop_duplicates()\n",
    "consumption_test = consumption_test.merge(pred_windows, on='series_id')\n",
    "\n",
    "num_cold_start_days_provided = (consumption_test.groupby('series_id')\n",
    "                                               .prediction_window\n",
    "                                               .value_counts()\n",
    "                                               .divide(24))\n",
    "\n",
    "num_cold_start_days_provided.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 19)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_series), len(test_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prediction windows for test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training set first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_groups = pd.DataFrame(data={'series_id':test_series, 'prediction_window':[random.choice(['hourly','daily','weekly']) for _ in range(len(test_series))]})\n",
    "test_window = pred_groups.merge(\n",
    "    consumption_test[consumption_test.series_id==pred_groups.series_id.values.tolist()[0]]\n",
    "                                .iloc[:50,:], on='series_id', how='inner')\n",
    "for i in pred_groups.series_id.values.tolist()[1:]:\n",
    "    test_window = pd.concat([test_window, pred_groups.merge(\n",
    "        consumption_test[consumption_test.series_id==i].iloc[:50,:], on='series_id', how='inner')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scoring_format(train_hours=40, pred_hours=10):\n",
    "    pred_scoring = test_window[test_window.series_id==pred_groups.series_id.values.tolist()[0]][train_hours:train_hours+pred_hours]\n",
    "    for j in pred_groups.series_id.values.tolist()[1:]:\n",
    "        pred_scoring = pd.concat([pred_scoring, test_window[test_window.series_id==j][train_hours:train_hours+pred_hours]])\n",
    "    pred_scoring.set_index('timestamp', inplace=True)\n",
    "    return pred_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scoring = create_scoring_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique series_id:  11\n"
     ]
    }
   ],
   "source": [
    "print('Unique series_id: ', test_window.series_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import load_model\n",
    "from subprocess import check_output\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_features(df, lag=1):\n",
    "    if not type(df) == pd.DataFrame:\n",
    "        df = pd.DataFrame(df, columns=['consumption'])\n",
    "    \n",
    "    def _rename_lag(ser, j):\n",
    "        ser.name = ser.name + f'_{j}'\n",
    "        return ser\n",
    "        \n",
    "    # add a column lagged by `i` steps\n",
    "    for i in range(1, lag + 1):\n",
    "        df = df.join(df.consumption.shift(i).pipe(_rename_lag, i))\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(consumption_series, lag):\n",
    "    \"\"\" Converts a series of consumption data into a\n",
    "        lagged, scaled sample.\n",
    "    \"\"\"\n",
    "    # scale training data\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    consumption_vals = scaler.fit_transform(consumption_series.values.reshape(-1, 1))\n",
    "    \n",
    "    # convert consumption series to lagged features\n",
    "    consumption_lagged = create_lagged_features(consumption_vals, lag=lag)\n",
    "\n",
    "    # X, y format taking the first column (original time series) to be the y\n",
    "    X = consumption_lagged.drop('consumption', axis=1).values\n",
    "    y = consumption_lagged.consumption.values\n",
    "    \n",
    "    # keras expects 3 dimensional X\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    \n",
    "    return X, y, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model(lag=24, num_neurons=24, batch_size=1, n_layers=1):\n",
    "    # model parameters\n",
    "    batch_input_shape=(batch_size, 1, lag)\n",
    "    \n",
    "    #set up model\n",
    "    model = Sequential()\n",
    "#     if n_layers==1:\n",
    "#         model.add(LSTM(units=num_neurons[0], batch_input_shape=batch_input_shape, stateful=True, dropout=0.2))\n",
    "#     elif n_layers>1:\n",
    "#         model.add(LSTM(units=num_neurons[0], batch_input_shape=batch_input_shape, stateful=True, return_sequences=True, dropout=0.2))\n",
    "#         for i in range(n_layers-1):\n",
    "#             model.add(LSTM(units=num_neurons[i+1], stateful=True, activation='relu', dropout=0.2))\n",
    "    if n_layers==1:\n",
    "        model.add(LSTM(units=num_neurons, batch_input_shape=batch_input_shape, stateful=True, dropout=0.2))\n",
    "    elif n_layers>1:\n",
    "        \n",
    "        for i in range(n_layers-1):\n",
    "            model.add(LSTM(units=num_neurons, batch_input_shape=batch_input_shape, stateful=True, return_sequences=True, dropout=0.2))\n",
    "        model.add(LSTM(units=num_neurons, stateful=True, activation='relu', dropout=0.2))    \n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, train_data, n_epochs=3, batch_size=1):\n",
    "    \"\"\" Fits model on training data on each series_id with specified\n",
    "        number of epochs.\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(n_epochs), total=n_epochs, desc='Learning Consumption Trends - Epochs'):\n",
    "        \n",
    "        # reset the LSTM state for training on each series\n",
    "        for ser_id, ser_data in train_data.groupby('series_id'):\n",
    "            # prepare the data\n",
    "            X, y, scaler = prepare_training_data(ser_data.consumption, lag)\n",
    "            #fit the model\n",
    "            model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "#             model.fit(X, y, epochs=1, batch_input_shape=(n_batch, train_X.shape[1], train_X.shape[2]),\n",
    "#                       verbose=1, shuffle=False)\n",
    "            model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hourly_forecast(num_pred_hours, consumption, model, scaler, lag, batch_size):\n",
    "    \"\"\" Uses last hour's prediction to generate next for num_pred_hours, \n",
    "        initialized by most recent cold start prediction. Inverts scale of \n",
    "        predictions before return.\n",
    "    \"\"\"\n",
    "   # allocate prediction frame\n",
    "    preds_scaled = np.zeros(num_pred_hours)\n",
    "    \n",
    "    # initial X is last lag values from the cold start\n",
    "    X = scaler.transform(consumption.values.reshape(-1, 1))[-lag:]\n",
    "    \n",
    "    # forecast\n",
    "    for i in range(num_pred_hours):\n",
    "        # predict scaled value for next time step\n",
    "        yhat = model.predict(X.reshape(1, 1, lag), batch_size=batch_size)[0][0]\n",
    "        preds_scaled[i] = yhat\n",
    "        \n",
    "        # update X to be latest data plus prediction\n",
    "        X = pd.Series(X.ravel()).shift(-1).fillna(yhat).values\n",
    "\n",
    "    # revert scale back to original range\n",
    "    hourly_preds = scaler.inverse_transform(preds_scaled.reshape(-1, 1)).ravel()\n",
    "    return hourly_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_complete_forecast(model, test_data, submission, lag=24, batch_size=1):\n",
    "    # set definitions of prediction windows\n",
    "    pred_window_to_num_preds = {'hourly': 24, 'daily': 7, 'weekly': 2}\n",
    "    pred_window_to_num_pred_hours = {'hourly': 24, 'daily': 7 * 24, 'weekly': 2 * 7 * 24}\n",
    "    \n",
    "    num_test_series = submission.series_id.nunique()\n",
    "    model.reset_states()\n",
    "    \n",
    "    for ser_id, pred_df in tqdm(submission.groupby('series_id'),\n",
    "                               total=num_test_series,\n",
    "                               desc=\"Forecasting from Cold Start Data\"):\n",
    "        \n",
    "        # get info about this series' prediction window\n",
    "        pred_window = pred_df.prediction_window.unique()[0]\n",
    "        num_preds = pred_window_to_num_preds[pred_window]\n",
    "        num_pred_hours = pred_window_to_num_pred_hours[pred_window]\n",
    "        \n",
    "        # prepare cold start data\n",
    "        series_data = consumption_test[consumption_test.series_id == ser_id].consumption\n",
    "        cold_X, cold_y, scaler = prepare_training_data(series_data, lag)\n",
    "        \n",
    "        # fine tune our lstm model to this site using cold start data    \n",
    "        model.fit(cold_X, cold_y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "\n",
    "        # make hourly forecasts for duration of pred window\n",
    "        preds = generate_hourly_forecast(num_pred_hours, series_data, model, scaler, lag, batch_size)\n",
    "\n",
    "        # reduce by taking sum over each sub window in pred window\n",
    "        reduced_preds = [pred.sum() for pred in np.split(preds, num_preds)]\n",
    "\n",
    "        # store result in submission DataFrame\n",
    "        ser_id_mask = my_submission.series_id == ser_id\n",
    "        my_submission.loc[ser_id_mask, 'consumption'] = reduced_preds\n",
    "        \n",
    "    return model, my_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(train, test, lag, num_neurons, batch_size, n_epochs, n_layers, train_hours=40, pred_hours=10):\n",
    "    # set up model architecture\n",
    "    pred_scoring = create_scoring_format()\n",
    "    model = set_model(lag=lag, num_neurons=num_neurons, batch_size=batch_size, n_layers=n_layers)\n",
    "    \n",
    "    # fit model on training data\n",
    "    model = fit_model(model, train, n_epochs=n_epochs, batch_size=batch_size)\n",
    "    \n",
    "    num_pred_hours = pred_hours\n",
    "    num_test_series = test.series_id.nunique()\n",
    "    scores = []\n",
    "    \n",
    "    for ser_id, pred_df in tqdm(test.groupby('series_id'),\n",
    "                           total=num_test_series,\n",
    "                           desc='Forecasting from Cold Start Data'):\n",
    "        series_data = test[test.series_id==ser_id].consumption[:train_hours]\n",
    "        cold_X, cold_y, scaler = prepare_training_data(series_data, lag)\n",
    "        model.fit(cold_X, cold_y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        y_pred = generate_hourly_forecast(num_pred_hours, series_data, model, scaler, lag, batch_size)\n",
    "        y_real = test[test.series_id==ser_id].consumption[train_hours:train_hours+pred_hours]\n",
    "        model.reset_states()\n",
    "        pred_scoring.loc[pred_scoring.series_id==ser_id,'prediction'] = y_pred\n",
    "        scores.append(RMSE(y_real, y_pred))\n",
    "    \n",
    "    return model, scores, pred_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_param = dict()\n",
    "exp_param = {'lag': [12, 12, 12, 12],\n",
    "            'num_neurons': [100, 100, 200, 200],\n",
    "            'batch_size': [1, 1, 1, 1],\n",
    "            'n_epochs':[10, 20, 10, 20],\n",
    "            'n_layers':[2, 4, 2, 4]}\n",
    "df_exp = pd.DataFrame(data=exp_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning Consumption Trends - Epochs:  20%|██        | 2/10 [10:08<40:47, 305.90s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c27c5d2f8baa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# train model and calculate score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     model, scores, pred_scoring = run_experiment(consumption_train, consumption_test, lag, num_neurons, batch_size,\n\u001b[0;32m---> 13\u001b[0;31m                                                     n_epochs, n_layers)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# save results to dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-48d3f7290c8a>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(train, test, lag, num_neurons, batch_size, n_epochs, n_layers, train_hours, pred_hours)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# fit model on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnum_pred_hours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_hours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-bff00ea3965e>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, train_data, n_epochs, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m#fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#             model.fit(X, y, epochs=1, batch_input_shape=(n_batch, train_X.shape[1], train_X.shape[2]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#                       verbose=1, shuffle=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred_dict = dict()\n",
    "for i in range(4):\n",
    "    \n",
    "    # set parameters for experiment\n",
    "    lag = df_exp.loc[i, 'lag']\n",
    "    num_neurons = df_exp.loc[i, 'num_neurons']\n",
    "    batch_size = df_exp.loc[i, 'batch_size']\n",
    "    n_epochs = df_exp.loc[i, 'n_epochs']\n",
    "    n_layers = df_exp.loc[i, 'n_layers']\n",
    "\n",
    "    # train model and calculate score\n",
    "    model, scores, pred_scoring = run_experiment(consumption_train, consumption_test, lag, num_neurons, batch_size,\n",
    "                                                    n_epochs, n_layers)\n",
    "        \n",
    "    # save results to dataframe\n",
    "    df_exp.loc[i, 'score'] = np.mean(scores)\n",
    "    pred_dict[i] = pred_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(train, test, submission_format, lag=12, num_neurons=100, batch_size=1, n_epochs=20, n_layers=2, model_name=None):\n",
    "    \n",
    "    # set up model architecture\n",
    "    model = set_model(lag=lag, num_neurons=num_neurons, batch_size=batch_size, n_layers=n_layers)\n",
    "    \n",
    "    # fit model on training data\n",
    "    model = fit_model(model, train, n_epochs=n_epochs, batch_size=batch_size)\n",
    "    \n",
    "    # save model\n",
    "    model.model.save(model_name)\n",
    "    \n",
    "    # create submission format\n",
    "    my_submission = submission_format.copy()\n",
    "    model, my_submission = generate_complete_forecast(model, test, my_submission, lag=lag, batch_size=batch_size)\n",
    "    my_submission.loc[my_submission.consumption<0,'consumption']=0\n",
    "    \n",
    "    return my_submission, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning Consumption Trends - Epochs:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "my_submission, model = create_submission(consumption_train, consumption_test, submission_format, lag=12, num_neurons=100, \n",
    "                                         batch_size=1, n_epochs=1, n_layers=2, model_name='my_model_20181008a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1321c5b438>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(1,1,figsize=(10,6))\n",
    "k = 1\n",
    "plt.plot(pred_scoring.loc[pred_scoring.series_id==test_series[k]].index, pred_scoring.loc[pred_scoring.series_id==test_series[k],'consumption'], label='consumption')\n",
    "plt.plot(pred_scoring.loc[pred_scoring.series_id==test_series[k]].index, pred_scoring.loc[pred_scoring.series_id==test_series[k],'prediction'], label='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add testing functions here\n",
    "\n",
    "- fit model to first part of test set\n",
    "- predict and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_window</th>\n",
       "      <th>series_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>consumption</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 00:00:00</td>\n",
       "      <td>101842.233424</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 01:00:00</td>\n",
       "      <td>105878.048906</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 02:00:00</td>\n",
       "      <td>91619.105008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 03:00:00</td>\n",
       "      <td>94473.706203</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 04:00:00</td>\n",
       "      <td>96976.755526</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 05:00:00</td>\n",
       "      <td>109154.512346</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 06:00:00</td>\n",
       "      <td>91909.721222</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 07:00:00</td>\n",
       "      <td>100895.387051</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 08:00:00</td>\n",
       "      <td>99821.982004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 09:00:00</td>\n",
       "      <td>91215.992196</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 10:00:00</td>\n",
       "      <td>92730.008921</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 11:00:00</td>\n",
       "      <td>85853.654319</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 12:00:00</td>\n",
       "      <td>105324.940629</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 13:00:00</td>\n",
       "      <td>84766.187198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 14:00:00</td>\n",
       "      <td>90048.839983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 15:00:00</td>\n",
       "      <td>96442.396682</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 16:00:00</td>\n",
       "      <td>82619.377104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 17:00:00</td>\n",
       "      <td>96076.782736</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 18:00:00</td>\n",
       "      <td>98326.714712</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 19:00:00</td>\n",
       "      <td>96114.281602</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 20:00:00</td>\n",
       "      <td>117263.642177</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 21:00:00</td>\n",
       "      <td>95448.676726</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 22:00:00</td>\n",
       "      <td>97051.753259</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-24 23:00:00</td>\n",
       "      <td>96653.327804</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-25 00:00:00</td>\n",
       "      <td>96081.470094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-25 01:00:00</td>\n",
       "      <td>96179.904618</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-25 02:00:00</td>\n",
       "      <td>95692.419356</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-25 03:00:00</td>\n",
       "      <td>118013.619502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-25 04:00:00</td>\n",
       "      <td>98462.648102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>daily</td>\n",
       "      <td>103088</td>\n",
       "      <td>2014-12-25 05:00:00</td>\n",
       "      <td>109013.891598</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 00:00:00</td>\n",
       "      <td>3622.652142</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 01:00:00</td>\n",
       "      <td>3603.685377</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 02:00:00</td>\n",
       "      <td>3780.708519</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 03:00:00</td>\n",
       "      <td>3843.931069</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 04:00:00</td>\n",
       "      <td>3587.879740</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 05:00:00</td>\n",
       "      <td>4185.332842</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 06:00:00</td>\n",
       "      <td>5076.770804</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 07:00:00</td>\n",
       "      <td>7441.294191</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 08:00:00</td>\n",
       "      <td>14651.826074</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 09:00:00</td>\n",
       "      <td>18144.871988</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 10:00:00</td>\n",
       "      <td>16428.379742</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 11:00:00</td>\n",
       "      <td>18571.624203</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 12:00:00</td>\n",
       "      <td>15808.798747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 13:00:00</td>\n",
       "      <td>13384.213937</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 14:00:00</td>\n",
       "      <td>11860.550470</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 15:00:00</td>\n",
       "      <td>11996.478954</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 16:00:00</td>\n",
       "      <td>11421.153744</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 17:00:00</td>\n",
       "      <td>10226.247540</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 18:00:00</td>\n",
       "      <td>7532.966890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 19:00:00</td>\n",
       "      <td>6726.879371</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 20:00:00</td>\n",
       "      <td>4400.289513</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 21:00:00</td>\n",
       "      <td>4134.754801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 22:00:00</td>\n",
       "      <td>4043.082103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-22 23:00:00</td>\n",
       "      <td>3527.818317</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-23 00:00:00</td>\n",
       "      <td>3749.097243</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-23 01:00:00</td>\n",
       "      <td>3480.401404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-23 02:00:00</td>\n",
       "      <td>3777.547391</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-23 03:00:00</td>\n",
       "      <td>3600.524250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-23 04:00:00</td>\n",
       "      <td>3628.974398</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>daily</td>\n",
       "      <td>100940</td>\n",
       "      <td>2017-09-23 05:00:00</td>\n",
       "      <td>3682.713565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1170 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_window  series_id           timestamp    consumption  \\\n",
       "0              daily     103088 2014-12-24 00:00:00  101842.233424   \n",
       "1              daily     103088 2014-12-24 01:00:00  105878.048906   \n",
       "2              daily     103088 2014-12-24 02:00:00   91619.105008   \n",
       "3              daily     103088 2014-12-24 03:00:00   94473.706203   \n",
       "4              daily     103088 2014-12-24 04:00:00   96976.755526   \n",
       "5              daily     103088 2014-12-24 05:00:00  109154.512346   \n",
       "6              daily     103088 2014-12-24 06:00:00   91909.721222   \n",
       "7              daily     103088 2014-12-24 07:00:00  100895.387051   \n",
       "8              daily     103088 2014-12-24 08:00:00   99821.982004   \n",
       "9              daily     103088 2014-12-24 09:00:00   91215.992196   \n",
       "10             daily     103088 2014-12-24 10:00:00   92730.008921   \n",
       "11             daily     103088 2014-12-24 11:00:00   85853.654319   \n",
       "12             daily     103088 2014-12-24 12:00:00  105324.940629   \n",
       "13             daily     103088 2014-12-24 13:00:00   84766.187198   \n",
       "14             daily     103088 2014-12-24 14:00:00   90048.839983   \n",
       "15             daily     103088 2014-12-24 15:00:00   96442.396682   \n",
       "16             daily     103088 2014-12-24 16:00:00   82619.377104   \n",
       "17             daily     103088 2014-12-24 17:00:00   96076.782736   \n",
       "18             daily     103088 2014-12-24 18:00:00   98326.714712   \n",
       "19             daily     103088 2014-12-24 19:00:00   96114.281602   \n",
       "20             daily     103088 2014-12-24 20:00:00  117263.642177   \n",
       "21             daily     103088 2014-12-24 21:00:00   95448.676726   \n",
       "22             daily     103088 2014-12-24 22:00:00   97051.753259   \n",
       "23             daily     103088 2014-12-24 23:00:00   96653.327804   \n",
       "24             daily     103088 2014-12-25 00:00:00   96081.470094   \n",
       "25             daily     103088 2014-12-25 01:00:00   96179.904618   \n",
       "26             daily     103088 2014-12-25 02:00:00   95692.419356   \n",
       "27             daily     103088 2014-12-25 03:00:00  118013.619502   \n",
       "28             daily     103088 2014-12-25 04:00:00   98462.648102   \n",
       "29             daily     103088 2014-12-25 05:00:00  109013.891598   \n",
       "..               ...        ...                 ...            ...   \n",
       "0              daily     100940 2017-09-22 00:00:00    3622.652142   \n",
       "1              daily     100940 2017-09-22 01:00:00    3603.685377   \n",
       "2              daily     100940 2017-09-22 02:00:00    3780.708519   \n",
       "3              daily     100940 2017-09-22 03:00:00    3843.931069   \n",
       "4              daily     100940 2017-09-22 04:00:00    3587.879740   \n",
       "5              daily     100940 2017-09-22 05:00:00    4185.332842   \n",
       "6              daily     100940 2017-09-22 06:00:00    5076.770804   \n",
       "7              daily     100940 2017-09-22 07:00:00    7441.294191   \n",
       "8              daily     100940 2017-09-22 08:00:00   14651.826074   \n",
       "9              daily     100940 2017-09-22 09:00:00   18144.871988   \n",
       "10             daily     100940 2017-09-22 10:00:00   16428.379742   \n",
       "11             daily     100940 2017-09-22 11:00:00   18571.624203   \n",
       "12             daily     100940 2017-09-22 12:00:00   15808.798747   \n",
       "13             daily     100940 2017-09-22 13:00:00   13384.213937   \n",
       "14             daily     100940 2017-09-22 14:00:00   11860.550470   \n",
       "15             daily     100940 2017-09-22 15:00:00   11996.478954   \n",
       "16             daily     100940 2017-09-22 16:00:00   11421.153744   \n",
       "17             daily     100940 2017-09-22 17:00:00   10226.247540   \n",
       "18             daily     100940 2017-09-22 18:00:00    7532.966890   \n",
       "19             daily     100940 2017-09-22 19:00:00    6726.879371   \n",
       "20             daily     100940 2017-09-22 20:00:00    4400.289513   \n",
       "21             daily     100940 2017-09-22 21:00:00    4134.754801   \n",
       "22             daily     100940 2017-09-22 22:00:00    4043.082103   \n",
       "23             daily     100940 2017-09-22 23:00:00    3527.818317   \n",
       "24             daily     100940 2017-09-23 00:00:00    3749.097243   \n",
       "25             daily     100940 2017-09-23 01:00:00    3480.401404   \n",
       "26             daily     100940 2017-09-23 02:00:00    3777.547391   \n",
       "27             daily     100940 2017-09-23 03:00:00    3600.524250   \n",
       "28             daily     100940 2017-09-23 04:00:00    3628.974398   \n",
       "29             daily     100940 2017-09-23 05:00:00    3682.713565   \n",
       "\n",
       "    temperature  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "5           NaN  \n",
       "6           NaN  \n",
       "7           NaN  \n",
       "8           NaN  \n",
       "9           NaN  \n",
       "10          NaN  \n",
       "11          NaN  \n",
       "12          NaN  \n",
       "13          NaN  \n",
       "14          NaN  \n",
       "15          NaN  \n",
       "16          NaN  \n",
       "17          NaN  \n",
       "18          NaN  \n",
       "19          NaN  \n",
       "20          NaN  \n",
       "21          NaN  \n",
       "22          NaN  \n",
       "23          NaN  \n",
       "24          NaN  \n",
       "25          NaN  \n",
       "26          NaN  \n",
       "27          NaN  \n",
       "28          NaN  \n",
       "29          NaN  \n",
       "..          ...  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "5           NaN  \n",
       "6           NaN  \n",
       "7           NaN  \n",
       "8           NaN  \n",
       "9           NaN  \n",
       "10          NaN  \n",
       "11          NaN  \n",
       "12          NaN  \n",
       "13          NaN  \n",
       "14          NaN  \n",
       "15          NaN  \n",
       "16          NaN  \n",
       "17          NaN  \n",
       "18          NaN  \n",
       "19          NaN  \n",
       "20          NaN  \n",
       "21          NaN  \n",
       "22          NaN  \n",
       "23          NaN  \n",
       "24          NaN  \n",
       "25          NaN  \n",
       "26          NaN  \n",
       "27          NaN  \n",
       "28          NaN  \n",
       "29          NaN  \n",
       "\n",
       "[1170 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting from Cold Start Data: 100%|██████████| 625/625 [13:19<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# copy submission format and fill in values\n",
    "my_submission = submission_format.copy()\n",
    "model, my_submission = generate_complete_forecast(model, consumption_test, my_submission, lag=lag, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.808000e+03\n",
       "mean     1.661096e+05\n",
       "std      6.193884e+05\n",
       "min     -3.393037e+04\n",
       "25%      1.511113e+04\n",
       "50%      3.704044e+04\n",
       "75%      9.533242e+04\n",
       "max      5.095149e+06\n",
       "Name: consumption, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission[my_submission.prediction_window == 'hourly'].consumption.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.337000e+03\n",
       "mean     3.406911e+06\n",
       "std      9.819808e+06\n",
       "min     -1.137587e+04\n",
       "25%      4.271856e+05\n",
       "50%      9.248156e+05\n",
       "75%      2.730388e+06\n",
       "max      1.156378e+08\n",
       "Name: consumption, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission[my_submission.prediction_window == 'daily'].consumption.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.840000e+02\n",
       "mean     2.435026e+07\n",
       "std      6.639902e+07\n",
       "min     -1.357406e+06\n",
       "25%      2.819529e+06\n",
       "50%      7.594946e+06\n",
       "75%      2.026643e+07\n",
       "max      7.481041e+08\n",
       "Name: consumption, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission[my_submission.prediction_window == 'weekly'].consumption.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.loc[my_submission.consumption<0,'consumption']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a23a31080>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEvCAYAAABWsfYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a23a31da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot samples\n",
    "sample_ser = (my_submission[my_submission.prediction_window == 'hourly']\n",
    "                           .series_id\n",
    "                           .sample().values[0])\n",
    "\n",
    "(my_submission[my_submission.series_id == sample_ser]\n",
    "              .plot(x='timestamp',\n",
    "                    y='consumption',\n",
    "                    title=sample_ser,\n",
    "                    rot=90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.iloc[:,:-1].to_csv(\"submissions/my_submmission_20181001_2.csv\", index_label='pred_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y, pred):\n",
    "    return mean_squared_error(y, pred)**0.5\n",
    "\n",
    "def MAE(y, pred):\n",
    "    return sum([abs(i) for i in (y-pred)])/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(train_size, test_size, data, limit=5800):\n",
    "    train = data[:train_size]\n",
    "    test  = data[train_size:limit]\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaler.fit(train)\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "    return scaler, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(train, test):\n",
    "    # Split into input and outputs \n",
    "    train_X, train_y = train[:,:-5], train[:,-5:]\n",
    "    test_X, test_y = test[:, :-5], test[:, -5:]\n",
    "    # LSTM requires 3D data sets: [samples, timesteps, features]\n",
    "    total_features = train_X.shape[1]\n",
    "    train_X = train_X.reshape(train_X.shape[0],7,int(total_features/7))\n",
    "    test_X = test_X.reshape(test_X.shape[0], 7,int(total_features/7))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(train_X, train_y, layers=3, n_batch=50, n_neurons=100, n_epochs=100, n_output=1, dropout=0):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neurons, batch_input_shape=(n_batch, train_X.shape[1], train_X.shape[2]),\n",
    "                 stateful=True, activation='tanh', return_sequences=True))\n",
    "    for i in range(layers-2):\n",
    "        model.add(LSTM(n_neurons, stateful=True, activation='tanh', return_sequences=True, dropout=dropout))\n",
    "    model.add(LSTM(n_neurons, stateful=True, activation='relu', dropout=dropout))\n",
    "    model.add(Dense(n_output))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    for i in range(int(train_X.shape[0] / n_batch)):\n",
    "        this_X = train_X[(i * n_batch):((i + 1) * n_batch)][:][:]\n",
    "        this_y = train_y[(i * n_batch):((i + 1) * n_batch)]\n",
    "        history = model.fit(this_X, this_y, epochs=n_epochs, \n",
    "                                    batch_size=n_batch, \n",
    "                                    verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model, history, n_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_X, test_y, scaler, n_batch, n_samples=1):\n",
    "\n",
    "    y_pred = [test_X.shape[0]]\n",
    "    for i in range(int(test_X.shape[0] / n_batch)):\n",
    "        this_X = test_X[(i * n_batch):((i + 1) * n_batch)][:][:]\n",
    "        this_pred = model.predict(this_X, batch_size=n_batch)    \n",
    "        y_pred[(i * n_batch):((i + 1) * n_batch)] = [list(i) for i in this_pred]\n",
    "    \n",
    "    test_X_nn = test_X.reshape((test_X.shape[0], test_X.shape[1]*test_X.shape[2]))\n",
    "    # Invert scaling for forecast\n",
    "    inv_y_pred = np.concatenate((y_pred, test_X_nn[:, :]), axis=1)\n",
    "    inv_y_pred = scaler.inverse_transform(inv_y_pred)\n",
    "    inv_y_pred = inv_y_pred[:,:5]\n",
    "    inv_y_pred = np.round(np.maximum(inv_y_pred, 0))\n",
    "    # Invert scaling for actual\n",
    "    test_y_nn = test_y.reshape((len(test_y), 5))\n",
    "    inv_y = np.concatenate((test_y_nn, test_X_nn[:, :]), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,:5]\n",
    "    # print scores\n",
    "    print(inv_y_pred[:10])\n",
    "    print(inv_y[:10])\n",
    "    rmse = dict()\n",
    "    for i in range(n_samples):\n",
    "        rmse[i] = RMSE([m[i]/4 for m in inv_y], [n[i]/4 for n in inv_y_pred])\n",
    "        print('Test RMSE: %.3f' % rmse[i])\n",
    "    \n",
    "    return rmse, inv_y_pred, inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_prediction(df, prediction):\n",
    "    pred_df = df.iloc[-prediction.shape[0]-26:-26,:]\n",
    "#     pred_df = df.iloc[-prediction.shape[0]-33:-33,:]\n",
    "    for i in range(prediction.shape[1]):\n",
    "        pred_df['prediction{}'.format(i)] = [x[i] for x in prediction]\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_baseline(data, n_samples):\n",
    "    baseline = dict()\n",
    "    for i in range(n_samples):\n",
    "        baseline[i] = data.iloc[:5100,:].groupby(['hour'])['swaps{}'.format(i)].quantile(.75)\n",
    "        baseline[i] = baseline[i].reset_index()\n",
    "        baseline[i].rename(columns={'swaps{}'.format(i):'baseline{}'.format(i)}, inplace=True)\n",
    "        data = data.merge(baseline[i], on='hour', how='left')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast_multi(data, range_lower=-700, range_upper=None, n_samples=1):\n",
    "    plt.subplots(n_samples, 1, figsize=(20,6*n_samples))\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(n_samples, 1, i+1)\n",
    "        plt.plot(data.iloc[range_lower:range_upper].index, np.round(data.iloc[range_lower:range_upper,i]/4), label='Real')\n",
    "        plt.plot(data.iloc[range_lower:range_upper].index, np.round(data.iloc[range_lower:range_upper,list(data.columns).index('prediction{}'.format(i))]/4), label='Predict')\n",
    "        plt.plot(data.iloc[range_lower:range_upper].index, np.round(data.iloc[range_lower:range_upper,list(data.columns).index('baseline{}'.format(i))]/4), label='Baseline')\n",
    "        plt.xlabel('Date Time', fontsize=16)\n",
    "        plt.ylabel('Swaps', fontsize=16)\n",
    "        plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(vmlist, layers, n_batch, n_neurons, n_epochs, dropout):\n",
    "    #select GoStations to forecast\n",
    "    df_station = df[df.vmid.isin(vmlist)]\n",
    "    df_station = pd.pivot_table(df_station, values='swaps', index='datetime', columns='vmid')\n",
    "    df_station['hour'] = df_station.index.hour\n",
    "    \n",
    "    #rename columns\n",
    "    cols = df_station.columns\n",
    "    for n, i in enumerate(cols[:-1]):\n",
    "        df_station.rename(columns={i:'swaps'+str(n)}, inplace=True)\n",
    "        \n",
    "    prep_df = pd.concat([df_station[list(df_station.columns)[:-1]], pd.get_dummies(df_station['hour'], prefix='hour')], axis=1)\n",
    "    prep_df.loc[prep_df.index.dayofweek>4, 'weekend'] = 1\n",
    "    prep_df['weekend'].fillna(0, inplace=True)\n",
    "    cols = prep_df.columns\n",
    "    tmp = pd.DataFrame(series_to_supervised(prep_df, 7, 1))\n",
    "    tmp.drop(tmp.columns[-(prep_df.shape[1] - len(vmlist)):], axis=1, inplace=True)\n",
    "    super_data = tmp\n",
    "    \n",
    "    #split train/test set and scale\n",
    "    scaler, train, test = create_train_test(5100, len(super_data)-5100-26, super_data)\n",
    "    train_X, train_y, test_X, test_y = split_train_test(train, test)\n",
    "    \n",
    "    #train model\n",
    "    model, history, n_batch = fit_lstm(train_X, train_y, layers, n_batch, n_neurons, n_epochs, len(vmlist), dropout)\n",
    "    rmse, inv_y_pred, inv_y = evaluate_model(model, test_X, test_y, scaler, n_batch, len(vmlist))\n",
    "    \n",
    "    #create dataframe with all predictions and real data\n",
    "    pred_prep_df = append_prediction(prep_df, inv_y_pred)\n",
    "    pred_prep_df['hour']=pred_prep_df.index.hour\n",
    "    pred_index = pred_prep_df.index\n",
    "    pred_prep_df = append_baseline(pred_prep_df, len(vmlist))\n",
    "    pred_prep_df.index = pred_index\n",
    "    \n",
    "    hyperparam = pd.DataFrame(data={'layers':[layers],'batch_size':[n_batch],'neurons':[n_neurons],'epochs':[n_epochs],'dropout':[dropout],\n",
    "                   'RMSE0':[rmse[0]],'RMSE1':[rmse[1]],'RMSE2':[rmse[2]],'RMSE3':[rmse[3]],'RMSE4':[rmse[4]]})\n",
    "    \n",
    "    return pred_prep_df, hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_results(df, vmlist, layers, n_batch, n_neurons, n_epochs, dropout):\n",
    "    pred_prep_df, hyperparam = run_experiment(vmlist, layers, n_batch, n_neurons, n_epochs, dropout)\n",
    "    df = df.append(hyperparam)\n",
    "    return df, pred_prep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag of 24 to simulate smallest cold start window. Our series\n",
    "# will be converted to a num_timesteps x lag size matrix\n",
    "lag =  24\n",
    "\n",
    "# model parameters\n",
    "num_neurons = 24\n",
    "batch_size = 1  # this forces the lstm to step through each time-step one at a time\n",
    "batch_input_shape=(batch_size, 1, lag)\n",
    "\n",
    "# instantiate a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# add LSTM layer - stateful MUST be true here in \n",
    "# order to learn the patterns within a series\n",
    "model.add(LSTM(units=num_neurons, \n",
    "              batch_input_shape=batch_input_shape, \n",
    "              stateful=True))\n",
    "\n",
    "# followed by a dense layer with a single output for regression\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning Consumption Trends - Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.1114\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1520\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1415\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1346\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1105\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1320\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.1142\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1187\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1007\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning Consumption Trends - Epoch:  33%|███▎      | 1/3 [00:14<00:28, 14.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0959\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.1438\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.1425\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.1332\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1060\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1288\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1093\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.1164\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0994\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning Consumption Trends - Epoch:  67%|██████▋   | 2/3 [00:29<00:14, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0968\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1421\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1420\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1324\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1050\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1263\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1099\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1160\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1006\n",
      "Epoch 1/1\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning Consumption Trends - Epoch: 100%|██████████| 3/3 [00:42<00:00, 14.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 12 s, total: 1min 13s\n",
      "Wall time: 42.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_training_series = consumption_train.series_id.nunique()\n",
    "num_passes_through_data = 3\n",
    "\n",
    "for i in tqdm(range(num_passes_through_data), \n",
    "              total=num_passes_through_data, \n",
    "              desc='Learning Consumption Trends - Epoch'):\n",
    "    \n",
    "    # reset the LSTM state for training on each series\n",
    "    for ser_id, ser_data in consumption_train.groupby('series_id'):\n",
    "\n",
    "        # prepare the data\n",
    "        X, y, scaler = prepare_training_data(ser_data.consumption, lag)\n",
    "\n",
    "        # fit the model: note that we don't shuffle batches (it would ruin the sequence)\n",
    "        # and that we reset states only after an entire X has been fit, instead of after\n",
    "        # each (size 1) batch, as is the case when stateful=False\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting from Cold Start Data: 100%|██████████| 625/625 [05:53<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 17s, sys: 1min 2s, total: 8min 19s\n",
      "Wall time: 5min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_window_to_num_preds = {'hourly': 24, 'daily': 7, 'weekly': 2}\n",
    "pred_window_to_num_pred_hours = {'hourly': 24, 'daily': 7 * 24, 'weekly': 2 * 7 * 24}\n",
    "\n",
    "num_test_series = my_submission.series_id.nunique()\n",
    "\n",
    "model.reset_states()\n",
    "\n",
    "for ser_id, pred_df in tqdm(my_submission.groupby('series_id'), \n",
    "                            total=num_test_series, \n",
    "                            desc=\"Forecasting from Cold Start Data\"):\n",
    "        \n",
    "    # get info about this series' prediction window\n",
    "    pred_window = pred_df.prediction_window.unique()[0]\n",
    "    num_preds = pred_window_to_num_preds[pred_window]\n",
    "    num_pred_hours = pred_window_to_num_pred_hours[pred_window]\n",
    "    \n",
    "    # prepare cold start data\n",
    "    series_data = consumption_test[consumption_test.series_id == ser_id].consumption\n",
    "    cold_X, cold_y, scaler = prepare_training_data(series_data, lag)\n",
    "    \n",
    "    # fine tune our lstm model to this site using cold start data    \n",
    "    model.fit(cold_X, cold_y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "    \n",
    "    # make hourly forecasts for duration of pred window\n",
    "    preds = generate_hourly_forecast(num_pred_hours, series_data, model, scaler, lag)\n",
    "    \n",
    "    # reduce by taking sum over each sub window in pred window\n",
    "    reduced_preds = [pred.sum() for pred in np.split(preds, num_preds)]\n",
    "    \n",
    "    # store result in submission DataFrame\n",
    "    ser_id_mask = my_submission.series_id == ser_id\n",
    "    my_submission.loc[ser_id_mask, 'consumption'] = reduced_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
